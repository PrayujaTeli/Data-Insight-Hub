# mention the directory where the data sets are present

dir_path = "File Directory Path"
print("The data sets are present in " + dir_path)

import pandas as pd

# Simulating the data
data = {
    "Country": ["Country A", "Country B", "Country C"],
    "Gender": ["Male", "Female", "Male"],
    "85+ years": [10, 15, 20],
    "75-84 years": [20, 25, 30],
    "65-74 years": [30, 35, 40],
    "55-64 years": [40, 45, 50],
    "45-54 years": [50, 55, 60],
    "35-44 years": [60, 65, 70],
    "25-34 years": [70, 75, 80],
    "15-24 years": [80, 85, 90]
}

# Creating DataFrame
dfSuicide = pd.DataFrame(data)

# Printing DataFrame
print(dfSuicide.to_string(index=False))


# Processing suicide data set
dfSuicideFiltered = dfSuicide.iloc[2:].reset_index(drop=True)
print(dfSuicideFiltered.to_string(index=False))


# Importing Population data set
dfPopulation = pd.read_csv(r"C:\Users\Srinivas Pai\Downloads\Data-Project\Population.csv")
pd.options.display.float_format = '{:,.3f}'.format
print(dfPopulation.to_string(index=False))


# Performing pre-processing on dataset
dfPopulationFiltered = dfPopulation.copy()

# Computing the values for population in 2019 using growth rate and population in 2020
dfPopulationFiltered['Population (2019)'] = dfPopulationFiltered['pop2020'] - (dfPopulationFiltered['pop2020'] ** (dfPopulationFiltered['GrowthRate'] / 100))
dfPopulationFiltered.drop(["pop2022", "pop2021", "pop2020", "pop2050", "pop2030", "pop2015", "pop2010", "pop2000", "pop1990", "pop1980", "pop1970", "area", "landAreaKm", "density", "GrowthRate", "WorldPercentage", "rank"], axis=1, inplace=True)
dfPopulationFiltered.columns = ["Abbrievation", "Country", "Population (2019)"]

print(dfPopulationFiltered.to_string(index=False))


from pprint import pprint
import pandas as pd
import random

filename1 = r"C:\Users\Srinivas Pai\Downloads\Data-Project\Human Resourses Data.csv"
dfHumanResourcesData = pd.read_csv(filename1)

# Function to calculate the count for 2019 based on percentage increase
def calculate_count_2019(row):
    percentage = random.randint(-3, 9)  # Random percentage increase
    year_diff = 2019 - row['Year']  # Calculate the difference between 2019 and the current year
    count_2019 = row['Psychiatrists working in mental health sector (per 100 000 population)']
    count_2019 *= (1 + (percentage / 100)) ** year_diff  # Apply percentage increase for each year difference
    return count_2019

# Applying the function to calculate counts for 2019
dfHumanResourcesData['New_Psychiatrist_count_2019'] = dfHumanResourcesData.apply(calculate_count_2019, axis=1)
dfHumanResourcesData['New_Nurses_count_2019'] = dfHumanResourcesData.apply(calculate_count_2019, axis=1)
dfHumanResourcesData['New_Social workers_count_2019'] = dfHumanResourcesData.apply(calculate_count_2019, axis=1)
dfHumanResourcesData['New_Psychologists_count_2019'] = dfHumanResourcesData.apply(calculate_count_2019, axis=1)

# Drop unnecessary columns
dfHumanResourcesData.drop(["year_diff"], axis=1, inplace=True)

# Reset index
dfHumanResourcesData.reset_index(drop=True, inplace=True)

# Print the DataFrame
pprint(dfHumanResourcesData)


# Dropping columns from Happiness index
dfHappinessIndexFiltered = dfHappinessIndex.drop(columns=['happiness2020', 'scoreDifference', 'happiness2019'])

# Renaming columns
dfHappinessIndexFiltered.columns = ["Happiness Rank", "Country", "Happiness Index"]

print(dfHappinessIndexFiltered)
import pandas as pd
import random

dfLiteracy = pd.read_csv(r"C:\Users\Srinivas Pai\Downloads\Data-Project\Literacy Rate.csv")

# Create a new column for the adjusted year 2019
dfLiteracy['Year_2019'] = dfLiteracy['dataYear']

# Loop through each row to calculate the literacy rate for 2019
for index, row in dfLiteracy.iterrows():
    percentage = random.randint(-3, 9)  # Random percentage increase
    temp = 2019 - row['dataYear']  # Calculate the difference between 2019 and the current year
    year_2019 = row['latestRate']  # Original literacy rate
    # Apply percentage increase for each year difference
    for _ in range(temp):
        year_2019 *= (1 + (percentage / 100))
    dfLiteracy.at[index, 'Year_2019'] = year_2019

# Drop unnecessary columns
dfLiteracy.drop(columns=['dataYear', 'latestRate'], inplace=True)

# Rename columns
dfLiteracy.rename(columns={'Year_2019': 'Literacy Rate (2019)'}, inplace=True)

print(dfLiteracy)
# Dropping unnecessary columns from the Literacy dataset
dfLiteracyFiltered = dfLiteracy.drop(columns=['dataYear', 'latestRate', 'Year_2019'])

# Renaming columns
dfLiteracyFiltered.columns = ["Country", "Literacy Rate in 2019"]

print(dfLiteracyFiltered)
import pandas as pd

# Importing Mental Health data set
dfMentalHealth = pd.read_csv(r"C:\Users\Srinivas Pai\Downloads\Data-Project\Mental Health Governance.csv")

# Dropping unnecessary columns
dfMentalHealthFiltered = dfMentalHealth.drop(['Year', 'Year the law was enacted (latest revision)', 'Publication year of the policy or plan (latest revision)'], axis=1)

# Resetting index
dfMentalHealthFiltered.reset_index(drop=True, inplace=True)

# Printing the filtered DataFrame
print(dfMentalHealthFiltered)

import pandas as pd

# Importing Drug Addiction data set
dfDrugAddiction = pd.read_csv(r"C:\Users\Srinivas Pai\Downloads\Data-Project\Drug Addiction.csv")

# Dropping the 'Code' column
dfDrugAddictionFiltered = dfDrugAddiction.drop(columns=['Code'])

# Renaming columns for clarity
dfDrugAddictionFiltered.columns = ["Country", "Year", "Prevalence of Substance Use Disorders (Age-standardized Percent)"]

# Printing the filtered DataFrame
print(dfDrugAddictionFiltered)

# Filtering the Drug Addiction dataset for the year 2019
dfDrugAddictionFiltered = dfDrugAddiction[dfDrugAddiction['Year'] == 2019].reset_index(drop=True)

# Dropping the index column
dfDrugAddictionFiltered.drop(columns=['index'], inplace=True)

# Printing the filtered DataFrame
print(dfDrugAddictionFiltered)
import pandas as pd
import random

dfFacilitiesData = pd.read_csv(r"C:\Users\Srinivas Pai\Downloads\Data-Project\Facilities Data.csv")

# Calculate the difference between 2019 and the year in the dataset
dfFacilitiesData['year_diff'] = 2019 - dfFacilitiesData['Year']

# Loop through each row to calculate facilities count for 2019
for index, row in dfFacilitiesData.iterrows():
    percentage = random.randint(-3, 9)  # Random percentage increase
    for _ in range(row['year_diff']):
        # Apply percentage increase for each year difference
        dfFacilitiesData.at[index, 'Mental hospitals (per 100 000 population)'] *= (1 + (percentage / 100))
        dfFacilitiesData.at[index, 'Mental health units in general hospitals (per 100 000 population)'] *= (1 + (percentage / 100))
        dfFacilitiesData.at[index, 'Mental health outpatient facilities (per 100 000 population)'] *= (1 + (percentage / 100))
        dfFacilitiesData.at[index, 'Mental health day treatment facilities (per 100 000 population)'] *= (1 + (percentage / 100))
        dfFacilitiesData.at[index, 'Community residential facilities (per 100 000 population)'] *= (1 + (percentage / 100))

# Drop the 'year_diff' column
dfFacilitiesData.drop(columns=['year_diff'], inplace=True)

# Reset index
dfFacilitiesData.reset_index(drop=True, inplace=True)

# Print the DataFrame
print(dfFacilitiesData)
# Dropping unwanted columns from the Facilities dataset
dfFacilitiesDataFiltered = dfFacilitiesData.drop(columns=['Year', 'Mental hospitals (per 100 000 population)', 'Mental health units in general hospitals (per 100 000 population)', 'Mental health outpatient facilities (per 100 000 population)', 'Mental health day treatment facilities (per 100 000 population)', 'Community residential facilities (per 100 000 population)'])

# Printing the filtered DataFrame
print(dfFacilitiesDataFiltered)
from bs4 import BeautifulSoup
import requests
import re

url = "https://www.worldometers.info/gdp/gdp-by-country/"
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')

countries = []
gdps = []
gdp_growth_rates = []

# Find the table containing GDP data
table = soup.find("table", {"id": "example2"})

# Iterate over each row in the table
for row in table.find_all("tr")[1:]:
    # Extract data from each cell in the row
    cells = row.find_all("td")
    country = cells[1].text.strip()
    gdp = cells[2].text.strip().replace(",", "")  # Remove commas from GDP values
    gdp_growth_rate = cells[3].text.strip()
    
    # Append data to respective lists
    countries.append(country)
    gdps.append(int(gdp))
    gdp_growth_rates.append(gdp_growth_rate)

# Print the scraped data
for i in range(len(countries)):
    print("Country:", countries[i])
    print("GDP (USD):", gdps[i])
    print("GDP Growth Rate (%):", gdp_growth_rates[i])
    print()

# Optional: If you want to save the data to a DataFrame
import pandas as pd

df = pd.DataFrame({
    "Country": countries,
    "GDP (USD)": gdps,
    "GDP Growth Rate (%)": gdp_growth_rates
})

print(df)
import pandas as pd

# Create DataFrames for country and GDP
dfCountry = pd.DataFrame(country, columns=['Country'])
dfGDP = pd.DataFrame(gdp, columns=['GDP'])

# Concatenate DataFrames for country and GDP
dfGdp = pd.concat([dfCountry, dfGDP], axis=1)

# Convert GDP growth percentage to float
gdp_growth_float = [float(x) for x in gdp_growth]

# Create DataFrame for GDP growth percentage
dfGDPGrowth = pd.DataFrame(gdp_growth_float, columns=['GDP Growth Percentage'])

# Concatenate GDP growth percentage DataFrame with existing DataFrame
dfGdpWithPercentage = pd.concat([dfGdp, dfGDPGrowth], axis=1)

# Add a 'Year' column with value 2017
dfGdpWithPercentage['Year'] = 2017

print(dfGdpWithPercentage)
import random
from pprint import pprint

# Initialize variables
percentage = 0
temp = 0
k = 0
r = dfGdpwithpercent.shape[0]

# Create a new column to store the difference between 2019 and the year in the dataset
dfGdpwithpercent['year_diff'] = dfGdpwithpercent['Year'] - 2019

# Loop through each row to simulate GDP growth for 2019
for i in dfGdpwithpercent['Country']:
    year = dfGdpwithpercent['Year']  # Year column
    
    temp = 2019 - year[k]  # Calculate the difference between 2019 and the current year
    dfGdpwithpercent.at[k, 'year_diff'] = temp  # Store the difference in the 'year_diff' column
    
    percentage = random.randint(-3, 9)  # Random percentage increase or decrease
    j = 0
    
    if k == r:
        break
    else:
        k += 1
        
        dfGdpwithpercent['gdp_2019'] = dfGdpwithpercent['gdp']  # Create a new column for GDP in 2019
        
        # Calculate GDP for 2019 using the random percentage increase or decrease
        while j != temp:
            dfGdpwithpercent['gdp_2019'] = dfGdpwithpercent['gdp_2019'] + (dfGdpwithpercent['gdp_2019'] * (percentage / 100))
            j += 1

# Reset index
dfGdpwithpercent.reset_index(drop=True, inplace=True)

# Print the DataFrame
pprint(dfGdpwithpercent.head(15))
# Dropping unwanted columns from the GDP with percentage DataFrame
dfGdpwithpercentFiltered = dfGdpwithpercent.drop(columns=['Year', 'year_diff', 'gdp'])

# Renaming columns
dfGdpwithpercentFiltered.columns = ["Country", "GDP Growth Rate (in %)", "GDP (2019)"]

# Printing the filtered DataFrame
print(dfGdpwithpercentFiltered)
# Exporting DataFrames to Excel files
dfPopulation.to_excel("dfPopulation.xlsx")
dfPopulationFiltered.to_excel("dfPopulationFiltered.xlsx")

dfHumanresoursesdata.to_excel("dfHumanresoursesdata.xlsx")
dfHumanresoursesdataFiltered.to_excel("dfHumanresoursesdataFiltered.xlsx")

dfHappinessindex.to_excel("dfHappinessindex.xlsx")
dfHappinessindexFiltered.to_excel("dfHappinessindexFiltered.xlsx")

dfLiteracy.to_excel("dfLiteracy.xlsx")
dfLiteracyFiltered.to_excel("dfLiteracyFiltered.xlsx")

dfDrugAddiction.to_excel("dfDrugAddiction.xlsx")
dfDrugAddictionFiltered.to_excel("dfDrugAddictionFiltered.xlsx")

dfFacilitiesData.to_excel("dfFacilitiesData.xlsx")
dfFacilitiesDataFiltered.to_excel("dfFacilitiesDataFiltered.xlsx")

# Merging all the pre-processed datasets
merged_df = pd.merge(dfPopulationFiltered, dfHumanresoursesdataFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfHappinessindexFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfLiteracyFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfDrugAddictionFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfFacilitiesDataFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfSuicideFiltered, how='outer', on="Country")
merged_df = pd.merge(merged_df, dfMental_Health, how='outer', on="Country")

# Exporting the merged DataFrame to an Excel file
merged_df.to_excel("merged_data.xlsx")

print(merged_df)
import numpy as np

# Loop through each column and fill missing values with NaN
for column in merged_df.columns:
    merged_df[column].fillna(np.nan, inplace=True)

# Fill missing values for the 'Year' column with '2019'
merged_df['Year'].fillna("2019", inplace=True)

# Drop the first column if needed (assuming it's an index column)
merged_df = merged_df.drop(merged_df.columns[0], axis=1)

# Print the DataFrame
print(merged_df)
# Printing statistics for null values
print(merged_df.isnull().sum())
# Convert the final merged dataset to CSV format
merged_df.to_csv("Final_merged_dataset.csv", index=False)

print("DataFrame is written to CSV file successfully.")

